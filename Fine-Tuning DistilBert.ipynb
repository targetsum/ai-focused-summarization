{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdNRLZ6zHrgS"
   },
   "source": [
    "# Install and import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFB0ilFFaJHz"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-Cw5qTIaPUT"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "import torch \n",
    "import copy\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap \n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils import data \n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcSmE8cxH2CQ"
   },
   "source": [
    "# Check for GPU\n",
    "\n",
    "Tesla T4 and P100 should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC1xNu8zaQub"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQcsuVRIaUMg"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qq-rh2x9aXBK"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4h2QeApIJON"
   },
   "source": [
    "# Prepare Data\n",
    "\n",
    "\n",
    "*   open labeled dataset as dataframe\n",
    "*   create datasplits with random seed\n",
    "*   select a split by changing the idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57DErbL7aZH8"
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"cleaned1000.json\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWFvy3oVyvWb"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "train_idx = []\n",
    "test_idx = []\n",
    "for train_index, test_index in kf.split(df):\n",
    "  train_idx.append(train_index)\n",
    "  test_idx.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bIJrqDrywNq"
   },
   "outputs": [],
   "source": [
    "idx = 0 # testing was executed with splits 0,1 and 2\n",
    "df_train = df.iloc[train_idx[idx]]\n",
    "df_test = df.iloc[test_idx[idx]]\n",
    "df_val = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh7a5u8-I1jm"
   },
   "source": [
    "# Chose model and tokenizer\n",
    "Replace the model name with one of the commented names to select on of the following models and its tokenizer from huggingface or local data:\n",
    "\n",
    "\n",
    "*   DistilBERT-cased/uncased\n",
    "*   DistilBERT-uncased DAPT\n",
    "\n",
    "For the DAPT models the tokenizers of the base model needs to be selected.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6f2yEsuakZ2"
   },
   "outputs": [],
   "source": [
    "# \"distilbert-base-cased\"\n",
    "# \"distilbert-base-uncased\"\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = \"distilbert-base-cased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQe9I7eOJUAi"
   },
   "source": [
    "# Tokenizer and DataLoaders\n",
    "\n",
    "The tokenizer creates the input for the pre-trained LMs and does the padding. The necessary outputs are:\n",
    "\n",
    "\n",
    "*   Sentences as text (techincally not needed but nice for testing)\n",
    "*   Labels\n",
    "*   Standard inputs: input_ids, attention_mask, segment_ids (BERT-only)\n",
    "*   Additional inputs: cls_ids, cls_mask\n",
    "\n",
    "The dataloaders use this function to create batches from the dataset which can be used by the LMs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpqI-x7wzIXt"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "MAX_SENTS = 15\n",
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1BzAyrKfBrG"
   },
   "outputs": [],
   "source": [
    "def tokenize_abstract(sentences, targets, max_len, max_sents, tokenizer):\n",
    "\n",
    "  encoding = tokenizer(sentences) \n",
    "\n",
    "  joint_input_ids = []\n",
    "  joint_attention_mask = []\n",
    "  x = 0\n",
    "\n",
    "  for n in range(len(encoding[\"input_ids\"])):\n",
    "    joint_input_ids.extend(encoding[\"input_ids\"][n])\n",
    "    joint_attention_mask.extend(encoding[\"attention_mask\"][n])\n",
    "\n",
    "  token_padding = [0] * (max_len - len(joint_input_ids))\n",
    "  sent_padding = [0] * (max_sents - len(sentences))\n",
    "\n",
    "  joint_input_ids.extend(token_padding)\n",
    "  joint_attention_mask.extend(token_padding)\n",
    "\n",
    "  joint_input_ids = torch.tensor(joint_input_ids).squeeze()\n",
    "  joint_attention_mask = torch.tensor(joint_attention_mask).squeeze()\n",
    "\n",
    "  labels = torch.tensor(targets)\n",
    "  labels = torch.cat((labels, torch.tensor(sent_padding)), 0).long()\n",
    "\n",
    "  cls_ids = [i for i, t in enumerate(joint_input_ids) if t == tokenizer.cls_token_id]\n",
    "  cls_ids.extend(sent_padding)\n",
    "  cls_ids = torch.tensor(cls_ids)\n",
    "  \n",
    "\n",
    "  cls_mask = torch.cat((torch.ones([len(sentences)]), torch.zeros([max_sents - len(sentences)])), 0).long()\n",
    "\n",
    "  abstract_text = \"<>\".join(sentences)\n",
    "\n",
    "  return {\n",
    "      \"sentences\": abstract_text,\n",
    "      \"labels\": labels,\n",
    "      \"input_ids\": joint_input_ids,\n",
    "      \"attention_mask\": joint_attention_mask,\n",
    "      \"cls_ids\": cls_ids,\n",
    "      \"cls_mask\": cls_mask\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7DOdE_yzagj"
   },
   "outputs": [],
   "source": [
    "class AbsClassDataset(data.Dataset):\n",
    "\n",
    "  def __init__(self, abstracts, targets, tokenizer, max_len, max_sents):\n",
    "    self.abstracts = abstracts\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "    self.max_sents = max_sents\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.abstracts)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    abstract = self.abstracts[item]\n",
    "    target = self.targets[item]\n",
    "\n",
    "    encoding = tokenize_abstract(abstract, target, max_len=self.max_len, max_sents = self. max_sents, tokenizer=self.tokenizer)\n",
    "\n",
    "    return {\n",
    "      \"abstract_text\": encoding[\"sentences\"],\n",
    "      \"labels\": encoding[\"labels\"],\n",
    "      \"input_ids\": encoding[\"input_ids\"],\n",
    "      \"attention_mask\": encoding[\"attention_mask\"],\n",
    "      \"cls_ids\": encoding[\"cls_ids\"],\n",
    "      \"cls_mask\": encoding[\"cls_mask\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2Rwn6L703s5"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, max_sents, batch_size):\n",
    "  ds = AbsClassDataset(\n",
    "      abstracts=df.Sentences.to_numpy(),\n",
    "      targets=df.Extractive.to_numpy(),\n",
    "      tokenizer=tokenizer,\n",
    "      max_len=max_len,\n",
    "      max_sents=max_sents\n",
    "  )\n",
    "\n",
    "  return data.DataLoader(\n",
    "      ds,\n",
    "      batch_size=batch_size,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXvA9V6e1eaa"
   },
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, MAX_SENTS, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, MAX_SENTS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp-jtp2NJwbG"
   },
   "source": [
    "# Summarization Layers\n",
    "\n",
    "Here, the two different options for summarization layers (or encoders as they are called in the code) are defined:\n",
    "\n",
    "\n",
    "*   The Classifier simply does a linear transformation followed by a softmax\n",
    "*   The TransformerInterEncoder from the BERtSumExt implementation, code is modified from the original repository (https://github.com/nlpyang/PreSumm). For some reason the transformer layers from pytorch do not feature positional encoding so this needs to be defined manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6iRhoHQssEs"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, hidden_size):\n",
    "      super(Classifier, self).__init__()\n",
    "      self.linear1 = nn.Linear(hidden_size, 1)\n",
    "      self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x, cls_mask):\n",
    "      h = self.linear1(x).squeeze(-1)\n",
    "      sent_scores = self.sigmoid(h) * cls_mask.float()\n",
    "      return sent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMelpxc5Z6zz"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "  def __init__(self, dropout, dim, max_len=5000):\n",
    "    pe = torch.zeros(max_len, dim)\n",
    "    position = torch.arange(0, max_len).unsqueeze(1)\n",
    "    div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
    "                          -(math.log(10000.0) / dim)))\n",
    "    pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "    pe = pe.unsqueeze(0)\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.register_buffer('pe', pe)\n",
    "    self.dropout = nn.Dropout(p=dropout)\n",
    "    self.dim = dim\n",
    "\n",
    "  def forward(self, emb, step=None):\n",
    "    emb = emb * math.sqrt(self.dim)\n",
    "    if (step):\n",
    "        emb = emb + self.pe[:, step][:, None, :]\n",
    "\n",
    "    else:\n",
    "        emb = emb + self.pe[:, :emb.size(1)]\n",
    "    emb = self.dropout(emb)\n",
    "    return emb\n",
    "\n",
    "  def get_emb(self, emb):\n",
    "    return self.pe[:, :emb.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Dv5bPROaBy6"
   },
   "outputs": [],
   "source": [
    "class TransformerInterEncoder(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, d_ff, heads, dropout, num_layers=0):\n",
    "    super(TransformerInterEncoder, self).__init__()\n",
    "    self.pos_emb = PositionalEncoding(dropout, d_model)\n",
    "    self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=d_model, \n",
    "        nhead=heads,\n",
    "        dim_feedforward=d_ff,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    self.transformer_encoder = nn.TransformerEncoder(\n",
    "        encoder_layer=self.encoder_layer,\n",
    "        num_layers=num_layers,\n",
    "        norm=nn.LayerNorm(d_model, eps=1e-6)\n",
    "    )\n",
    "    self.linear1 = nn.Linear(d_model, 1, bias=True)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, sents_vec, mask):\n",
    "    batch_size, n_sents = sents_vec.size(0), sents_vec.size(1)\n",
    "    pos_emb = self.pos_emb.pe[:, :n_sents]\n",
    "    x = sents_vec * mask[:, :, None].float()\n",
    "    x = x + pos_emb\n",
    "    x = torch.transpose(x, 0, 1)\n",
    "    x = self.transformer_encoder(x, src_key_padding_mask=(1-mask).bool())\n",
    "    x = torch.transpose(x, 0, 1)\n",
    "\n",
    "    h = self.linear1(x).squeeze(-1)\n",
    "    sent_scores = self.sigmoid(h) * mask.float()\n",
    "\n",
    "    return sent_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YilamDAOJ-ff"
   },
   "source": [
    "# Abstract Summarizer\n",
    "The abstract summarizer defines the configuration of the model. Here, can be defined how the sentence representations are formed (cls token or pooling) and from which layer or layer combinations the representations are used (default is last hidden layer). Which encoder is used can be defined when the model is initialized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN4hTVvp2ru7"
   },
   "outputs": [],
   "source": [
    "def pool_sents(top_vec, cls_ids, attention_mask):\n",
    "  sents_vec = torch.zeros([top_vec.size(0), MAX_SENTS, top_vec.size(2)], dtype=torch.float32).to(device)\n",
    "  for s in range(top_vec.size(0)):\n",
    "    for i in range(14):\n",
    "      padding = False\n",
    "      if cls_ids[s, i+1].item() == 0:\n",
    "        if cls_ids[s, i].item() != 0:\n",
    "          sent_start = cls_ids[s, i].item()\n",
    "          sent_end = torch.sum(attention_mask[s]).item() - 2\n",
    "        else:\n",
    "          padding = True\n",
    "      else:\n",
    "        sent_start = cls_ids[s, i].item()\n",
    "        sent_end = cls_ids[s, i+1].item() - 2\n",
    "      if not padding:\n",
    "        sents_vec[s, i] = torch.mean(top_vec[s, sent_start:sent_end], 0).to(device)\n",
    "  return sents_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uJThcFETQTy"
   },
   "outputs": [],
   "source": [
    "class AbstractSummarizer(nn.Module):\n",
    "\n",
    "  def __init__(self, encoder):\n",
    "    super(AbstractSummarizer, self).__init__()\n",
    "    self.bert = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, output_hidden_states=True)\n",
    "    if encoder == \"transformer\":\n",
    "      self.encoder = TransformerInterEncoder(self.bert.config.hidden_size,\n",
    "                                             2048, 8, 0.1, num_layers=2)\n",
    "    else:\n",
    "      self.encoder = Classifier(self.bert.config.hidden_size)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, cls_ids, cls_mask):\n",
    "    outputs = self.bert(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "    )\n",
    "    top_vec = outputs.last_hidden_state # last hidden layer\n",
    "    #top_vec = outputs.hidden_states[1] # single layer\n",
    "    #top_vec = (1/3) * (outputs.hidden_states[1] + outputs.hidden_states[2] + outputs.hidden_states[6]) # combination of different layers\n",
    "    #sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), cls_ids]  # sent representations = CLS tokens\n",
    "    sents_vec = pool_sents(top_vec, cls_ids, attention_mask)  # sent representations = pooled over all tokens\n",
    "    sents_vec = sents_vec * cls_mask[:, :, None].float()\n",
    "    sent_scores = self.encoder(sents_vec, cls_mask).squeeze(-1)\n",
    "    return sent_scores, cls_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr3kUCdFKci7"
   },
   "source": [
    "# Sentence Selection\n",
    "\n",
    "Here, the sentences for the summary of each abstract are selected based on the selection strategy:\n",
    "\n",
    "\n",
    "*   Best-3: select 3 highest scoring sentences\n",
    "*   Dynamic: select sentence based on threshold, then add/remove highest/lowest scoring sentences if the prediction was outside of the allowed sentence range (1-4)\n",
    "\n",
    "To change the strategy, uncomment the indicated lines and comment the lines for the other strategy (a bit messy, sorry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYTV5OZSlunD"
   },
   "outputs": [],
   "source": [
    "def select_sents(sent_scores, labels, cls_mask, test_mode=False):\n",
    "\n",
    "  abs_accs = []\n",
    "  abs_prec = []\n",
    "  abs_rec = []\n",
    "  prec = 0\n",
    "  rec = 0\n",
    "  preds_len = np.array([0,0,0,0])\n",
    "  gold_len = np.array([0,0,0,0])\n",
    "\n",
    "\n",
    "  sent_scores = sent_scores.cpu().data.numpy()\n",
    "\n",
    "  # Best-3\n",
    "  selected_sents = np.argsort(-sent_scores, 1) \n",
    "  selected_sents = selected_sents[:,:3]\n",
    "  selected_sents = torch.tensor(selected_sents)\n",
    "  ones = torch.ones(sent_scores.shape, dtype=torch.int64)\n",
    "  selected_sents = torch.zeros(sent_scores.shape, dtype=torch.int64).scatter(1, selected_sents, ones).to(device)\n",
    "\n",
    "  # Dynamic\n",
    "  # selected_sents = (sent_scores > 0.5).astype(int)\n",
    "  # selected_sents = torch.tensor(selected_sents).to(device)\n",
    "\n",
    "  abs_len = cls_mask.sum(dim=1).int() #always leave this and the following three lines uncommented\n",
    "\n",
    "  for i in range(len(cls_mask)):\n",
    "    abs_labels = labels[i][:abs_len[i]]\n",
    "    preds = selected_sents[i, :abs_len[i]]\n",
    "    preds = preds.cpu().data.numpy()\n",
    "\n",
    "    # if preds.sum() == 0:\n",
    "    #   sentence_scores = sent_scores[i][:abs_len[i]]\n",
    "    #   sorted_sents = np.argsort(-sentence_scores)\n",
    "    #   preds[sorted_sents[0]] = 1\n",
    "\n",
    "    # elif preds.sum() > 4:\n",
    "    #   sentence_scores = sent_scores[i][:abs_len[i]]\n",
    "    #   sorted_sents = np.argsort(-sentence_scores)\n",
    "    #   preds = np.zeros(preds.size, dtype=int)\n",
    "    #   for p in range(4):\n",
    "    #     preds[sorted_sents[p]] = 1\n",
    "\n",
    "    # selected_sents[i, :abs_len[i]] = torch.tensor(preds).to(device)\n",
    "    # until here\n",
    "\n",
    "    correct = 0\n",
    "    correct_pos = 0\n",
    "\n",
    "    for j in range(len(abs_labels)):\n",
    "      if abs_labels[j] == preds[j]:\n",
    "        correct += 1\n",
    "        if test_mode and abs_labels[j] == 1:\n",
    "          correct_pos += 1\n",
    "\n",
    "    if test_mode:\n",
    "      abs_labels = abs_labels.cpu().data.numpy()\n",
    "      prec = correct_pos / preds.sum()\n",
    "      rec = correct_pos / abs_labels.sum()\n",
    "      for k in range(len(abs_labels)):\n",
    "        abs_prec.append(prec)\n",
    "        abs_rec.append(rec)\n",
    "      preds_len[preds.sum()-1] += 1\n",
    "      gold_len[abs_labels.sum()-1] += 1\n",
    "\n",
    "    #all abstracts weighted the same\n",
    "    #abs_accs.append(correct / len(abs_labels)) \n",
    "    \n",
    "    #accuracy weighted by abstract length\n",
    "    acc = correct / len(abs_labels)\n",
    "    for k in range(len(abs_labels)):\n",
    "      abs_accs.append(acc)\n",
    "\n",
    "  if test_mode:\n",
    "    return selected_sents, np.mean(abs_accs), np.mean(abs_prec), np.mean(abs_rec), preds_len, gold_len\n",
    "\n",
    "  else:\n",
    "    return selected_sents, np.mean(abs_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDbqtMZfLS-W"
   },
   "source": [
    "# Initialize the model\n",
    "\n",
    "chose the summary layer by changing the encoder variable (\"classifier\" or \"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vjq7zVmRvKLM"
   },
   "outputs": [],
   "source": [
    "model = AbstractSummarizer(encoder=\"transformer\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4QXEFAtLdzy"
   },
   "source": [
    "# Training and validation\n",
    "\n",
    "Here the actual fine-tuning happens. First, the hyperparameters and some metrics are defined. Then the training and evaluation functions are defined and called. During the training process, multiple stats are returned at the end of every epoch including: loss, accuraccy, precision, eecall, f1 score, length Loss and the length distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDUdWuMImu8p"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 7\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction=\"none\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcOygdg6zucU"
   },
   "outputs": [],
   "source": [
    "def length_loss(preds, labels):\n",
    "\n",
    "  losses = []\n",
    "  \n",
    "  for i in range(len(preds)):\n",
    "    loss = (preds[i] - labels[i])**2\n",
    "    if preds[i] < labels[i]:\n",
    "      loss = loss * 2\n",
    "    losses.append(loss.item())\n",
    "\n",
    "  return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDFLxk44ukLI"
   },
   "outputs": [],
   "source": [
    "def f1_score(prec, rec):\n",
    "  f1 = 2*((prec*rec)/(prec+rec))\n",
    "  # \"balanced f1:\"  2*((prec*rec)/(prec+rec)) - difference(prec, rec)*0.2\n",
    "  return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RK39-JHLwNHA"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n",
    "\n",
    "  model = model.train()\n",
    "  \n",
    "  losses = []\n",
    "  len_losses = []\n",
    "  accuracies = []\n",
    "\n",
    "  for batch in data_loader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    cls_ids = batch[\"cls_ids\"].to(device)\n",
    "    cls_mask = batch[\"cls_mask\"].to(device)\n",
    "\n",
    "    sent_scores, cls_mask = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        cls_ids=cls_ids,\n",
    "        cls_mask=cls_mask\n",
    "    )\n",
    "\n",
    "    loss = loss_fn(sent_scores, labels.float()).sum()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    selected_sents, abs_acc = select_sents(sent_scores, labels, cls_mask)\n",
    "    accuracies.append(abs_acc)\n",
    "\n",
    "    len_loss = length_loss(torch.sum(selected_sents, dim=1, dtype=float), torch.sum(labels, dim=1, dtype=float))\n",
    "    len_losses.append(len_loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return np.mean(accuracies), np.mean(losses), np.mean(len_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx_KTd5UGclV"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, test_mode=False):\n",
    "\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  len_losses = []\n",
    "  accuracies = []\n",
    "  prec = []\n",
    "  rec = []\n",
    "  preds_len_sum = np.array([0,0,0,0])\n",
    "  gold_len_sum = np.array([0,0,0,0])\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "      input_ids = batch[\"input_ids\"].to(device)\n",
    "      attention_mask = batch[\"attention_mask\"].to(device)\n",
    "      labels = batch[\"labels\"].to(device)\n",
    "      cls_ids = batch[\"cls_ids\"].to(device)\n",
    "      cls_mask = batch[\"cls_mask\"].to(device)\n",
    "      labels = batch[\"labels\"].to(device)\n",
    "\n",
    "      sent_scores, cls_mask = model(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask,\n",
    "          cls_ids=cls_ids,\n",
    "          cls_mask=cls_mask\n",
    "      )\n",
    "\n",
    "      loss = loss_fn(sent_scores, labels.float()).sum()\n",
    "      losses.append(loss.item())\n",
    "\n",
    "      if test_mode:\n",
    "        selected_sents, abs_acc, abs_prec, abs_rec, preds_len, gold_len = select_sents(sent_scores, labels, cls_mask, test_mode=True)\n",
    "        accuracies.append(abs_acc)\n",
    "        prec.append(abs_prec)\n",
    "        rec.append(abs_rec)\n",
    "        preds_len_sum += preds_len\n",
    "        gold_len_sum += gold_len\n",
    "        len_loss = length_loss(torch.sum(selected_sents, dim=1, dtype=float), torch.sum(labels, dim=1, dtype=float))\n",
    "        len_losses.append(len_loss.item())\n",
    "\n",
    "      else:\n",
    "        selected_sents, abs_acc = select_sents(sent_scores, labels, cls_mask)\n",
    "        accuracies.append(abs_acc)\n",
    "\n",
    "  if test_mode:\n",
    "    return np.mean(accuracies), np.mean(losses), np.mean(len_losses), np.mean(prec), np.mean(rec), preds_len_sum, gold_len_sum\n",
    "  else:\n",
    "    return np.mean(accuracies), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1a25btKd0Cd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss, train_len_loss = train_epoch(\n",
    "      model,\n",
    "      train_data_loader,\n",
    "      loss_fn,\n",
    "      optimizer,\n",
    "      device,\n",
    "      scheduler,\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {round(train_loss, 4)} accuracy {round(train_acc, 4)}')\n",
    "  print(f\"Train len loss {round(train_len_loss, 4)}\")\n",
    "\n",
    "\n",
    "  val_acc, val_loss, val_len_loss, pos_prec, pos_rec, preds_len, gold_len = eval_model(\n",
    "    model,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    test_mode=True\n",
    "  )\n",
    "\n",
    "  f1 = f1_score(pos_prec, pos_rec)\n",
    "\n",
    "  print(f'Val loss {round(val_loss, 4)} accuracy {round(val_acc, 4)}')\n",
    "  print(f\"Val len loss {round(val_len_loss, 4)}\")\n",
    "  print(f\"Precision: {round(pos_prec, 4)} Recall: {round(pos_rec, 4)}\")\n",
    "  print(f\"F1-score: {round(f1, 4)}\")\n",
    "  print(f\"Predictions distribution: {preds_len}\")\n",
    "  print(f\"Labels distribution: {gold_len}\")\n",
    "  print()\n",
    "\n",
    "  if f1 > best_f1:\n",
    "    #torch.save(model.state_dict(), 'best_distilbert_summarizer.bin')\n",
    "    best_f1 = f1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPjrLgResS7ttkKfPimQf/t",
   "collapsed_sections": [],
   "mount_file_id": "1YVZuvwlhYlvFlxSairAXvd9Z1VNWZUnu",
   "name": "Fine-Tuning DistilBert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
